<div class="header-bg-wrapper" style="border: none;">
    
    <section class="project-header-section no-bg white-text">

      <h1 class="h1-responsive mb-3 text-center px-md-0 px-2" style="color:#212529;">Augmented Reality</h1>

      <h2 class="h2-responsive mb-3 text-center px-md-0 px-2" style="color:#212529;">Enhancing the Physical World</h2>

    </section>

</div>

<div class="container">
	

	<section class="section">
		<div class="row mb-5">
	
			<div class="col-12">
			
				<figure class="mb-5 mx-auto text-center">
				
				    <img src="https://michaelladt.imgix.net/img/tech2a.jpg" class="img-fluid z-depth-1" alt="Augmented Reality" />
				
				</figure>
	




			    <h3 class="text-left text-uppercase project-h3" data-wow-delay="0.2s">Tech <strong>Exploration</strong></h4>
			    <p class="text-left my-4">Another subject I am very familiar with, Augmented Reality has significantly progressed throughout the years. Luckily we are no longer holding Q/R Codes up to our computer webcam to trigger sub-par experiences. My skill and knowledge of AR are mostly thanks to the Aurasma platform. The best part about Aurasma is that it was a somewhat free, plug, and play platform. Aurasma also used image recognition technology, and this means that all the developer has to do is download an image or take a picture and upload it as a trigger. You can then create an experience triggered by looking at the image using the application with your camera view on a tablet or smartphone. Aurasma was acquired by HP in 2017 and became HP Reveal.</p>
				    
				<h3 class="text-left text-uppercase project-h3 pt-3" data-wow-delay="0.2s">The <strong>Future</strong></h4>
				<p class="text-left my-4">After my experience with Aurasma, I was fortunate enough to meet some kind people from Specular Theory; at the time, they had created a revolutionary AR platform. While there was no plug-and-play interface, it did not have the limitations Aurasma might have. Specular Theory used cloud-based, real-time rendering. To put it simply, you can get film quality 3D objects/animation along with the gesture-based interactions that come equipped with our mobile devices. This is where Aurasma fell short, their 3D engine is not film quality, and you cannot do anything except click or move the camera to interact. It was clear to me, the future of AR was in real-time rendering over the cloud. I couldn't have been more right.</p>
	    
	    
	      		<h3 class="text-left text-uppercase project-h3 pt-3" data-wow-delay="0.2s">Hacking <strong>AR</strong></h3>
	      		<p class="text-left my-4"> When I first arrived at Team One and was settled in, the ECD handed me credentials for an Aurasma studio account. Incidentally, I had been teaching myself Maya, and I had also just finished a project for school where I used ActionScript3 and PaperVision3D to create a primitive A/R experience. After a month of exploration, we knew the platform's capabilities. We had pushed the limits and even found workarounds for functionality that didn't even exist. We built several rapid prototypes, and when we met with Aurasma, they were quite surprised when we showed them specific capabilities of which they were not even aware. To view the first few prototypes <a class="text-link" href="./downloads/AurasmaDeck.pdf" target="_blank">click here</a></p>.
		    
		  		<figure class="mb-5 mx-auto text-center">
		    
		  			<img src="https://michaelladt.imgix.net/img/tech2b.jpg" alt="Michael Ladt's A/R Prototype" class="img-fluid z-depth-1" />
		  			
		  		</figure>
		    
		    
	      		<h3 class="text-left text-uppercase project-h3 pt-3" data-wow-delay="0.2s">The Importance of <strong>Exploration</strong></h3>
	      		<p class="text-left mt-4">My Creative Technologist position at Team One was unique as I was a hybrid between the Creative Department and the Media Department. Media approached me about an opportunity with Esquire magazine. Hearst Publishing had purchased Netpage, which, for the most part, was image recognition technology. They wanted to use it on every page of every issue of the magazine moving forward. Using Netpage with the magazine triggered high-resolution images that the user could clip and share via social media. Depending on the content you were viewing, there could be an option to purchase a movie ticket, download a song, or book a flight. Lexus was the only advertiser that Esquire offered an enhanced experience. Once I explored their SDK/Demo and spoke to their developers, I knew there was very little we could do to enhance the experience.</p>
		      		
		      	<p class="text-left mb-4">Fortunately, I had a great solution. I had seen an Aurasma advertisement created by an automobile company. Not only did the video extend out from the page itself, but it was also just a video thrown onto a page. There was no transition or integration whatsoever. I decided that my best recommendation was to overlay a borderless video onto the page. Once I saw the advertisement we were using in Esquire for the Lexus LS, it was apparent. We could use After Effects to bring the scene to life, cars driving by, lights flashing, the car starting, and then it could transition into the 30-second commercial. Creating a seamless user experience and truly bringing the page to life. The other creatives tried their best to come up with new ideas and executions, which were all fantastic, but it wasn't the time for concepting. It was one of those situations where I explained, "This is why I am here. I understand the full capabilities of their technology, we are very limited in what we can do,  and gestures are not available. I have been researching this for weeks, and this is our best use of the platform. I am not killing your ideas. They are simply not possible from a technology standpoint."</p>
		    
		  		<figure class="mb-5 mx-auto text-center">
		  		
		  			<img src="https://michaelladt.imgix.net/img/tech2d.jpg" alt=" A/R Project for Lexus and Esquire" class="img-fluid z-depth-1" />
		  			
		  		</figure>
		    
	      		<h3 class="text-left text-uppercase project-h3 pt-3" data-wow-delay="0.2s">Rapid <strong>Prototyping</strong></h3>
	      		<p class="text-left my-4"> I built many prototypes using Aurasma. The first was a 2D car configurator, which let you choose the color, trim, and wheels for a Lexus LFA. Using photos of an Acrylic LFA built by a Japanese artist, I made another prototype where the car looked transparent with 12 views creating a 360-degree experience. We then started to use physical objects which could trigger a check-in on Foursquare or automate a tweet. Late in 2013, I created a prototype using an LFA that I had modeled in Maya just as a fun side project. Using my 3D model, I created a 3D color configurator for the Lexus Supercar. The trick to this was never changing out any objects that didn't have paint. Working with 3D files can be very challenging, but I simplified it, and I referred to my workaround as the car's <em>skeleton</em>. Keeping the skeleton active and only changing the shell optimized the experience and kept load times down. The prototype transitioned to the ignition sequence video and then to an image gallery. I presented the prototype to our Lexus clients, who were thrilled by the technology and my ability to create. My work was featured in the 2014 Sports Illustrated Swimsuit Edition.</p>
		    
		  		<figure class="mb-5 mx-auto text-center">
		  		
		  			<img src="https://michaelladt.imgix.net/img/tech2c.jpg" alt="A/R Project for Lexus and the Sports Illustrated Swimsuit Edition" class="img-fluid z-depth-1" />
		  		
		  		</figure>
			
			</div>
			
		</div>
	</section>
</div>
